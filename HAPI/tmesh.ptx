//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_52
.address_size 64

	// .globl	__raygen__rg
.const .align 8 .b8 params[32];
.global .align 1 .b8 _ZN63_INTERNAL_41_tmpxft_000065f8_00000000_11_tmesh_cpp1_ii_debcdc516thrust6system6detail10sequential3seqE[1];
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry __raygen__rg(

)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .f32 	%f<293>;
	.reg .b32 	%r<172>;
	.reg .f64 	%fd<16>;
	.reg .b64 	%rd<49>;


	mov.u64 	%SPL, __local_depot0;
	add.u64 	%rd1, %SPL, 0;
	// inline asm
	call (%r68), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r69), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r71), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%rd19), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.v2.f32 	{%f93, %f94}, [%rd19];
	mov.u32 	%r154, 0;
	ld.v2.f32 	{%f97, %f98}, [%rd19+8];
	ld.v2.f32 	{%f101, %f102}, [%rd19+16];
	ld.v2.u32 	{%r75, %r76}, [%rd19+24];
	cvt.rn.f32.u32	%f103, %r68;
	fma.rn.f32 	%f104, %f103, %f97, %f93;
	and.b32  	%r78, %r69, 1;
	setp.eq.b32	%p1, %r78, 1;
	not.pred 	%p2, %p1;
	setp.ne.s32	%p3, %r75, 0;
	and.pred  	%p4, %p2, %p3;
	fma.rn.f32 	%f105, %f97, 0f3F000000, %f104;
	selp.f32	%f3, %f105, %f104, %p4;
	cvt.rn.f32.u32	%f106, %r69;
	mul.f32 	%f107, %f106, %f98;
	sub.f32 	%f4, %f94, %f107;
	ld.u32 	%r5, [%rd19+32];
	mov.f32 	%f258, 0f00000000;
	setp.lt.s32	%p5, %r5, 1;
	mov.f32 	%f259, %f258;
	mov.f32 	%f260, %f258;
	mov.f32 	%f261, %f258;
	mov.f32 	%f262, %f258;
	mov.f32 	%f263, %f258;
	@%p5 bra 	BB0_40;

	add.s64 	%rd3, %rd19, 40;
	add.s64 	%rd5, %rd1, 24;
	mov.f32 	%f277, 0f00000000;
	mov.u32 	%r151, 0;
	mov.u32 	%r154, %r151;
	mov.f32 	%f278, %f277;
	mov.f32 	%f279, %f277;
	mov.f32 	%f280, %f277;
	mov.f32 	%f258, %f277;
	mov.f32 	%f259, %f277;
	mov.f32 	%f260, %f277;
	mov.f32 	%f261, %f277;
	mov.f32 	%f262, %f277;
	mov.f32 	%f263, %f277;

BB0_2:
	setp.lt.s32	%p6, %r76, 1;
	@%p6 bra 	BB0_39;

	mov.u32 	%r153, 0;

BB0_4:
	mul.lo.s32 	%r144, %r151, %r76;
	mov.u32 	%r143, 0;
	neg.f32 	%f228, %f101;
	ld.const.u64 	%rd42, [params+8];
	add.s32 	%r97, %r153, %r144;
	ld.u64 	%rd22, [%rd3];
	mul.wide.s32 	%rd23, %r97, 8;
	add.s64 	%rd24, %rd22, %rd23;
	ld.v2.f32 	{%f127, %f128}, [%rd24];
	cvt.f64.f32	%fd1, %f127;
	cvt.f64.f32	%fd2, %f128;
	mul.f64 	%fd3, %fd2, %fd2;
	fma.rn.f64 	%fd4, %fd1, %fd1, %fd3;
	add.f64 	%fd5, %fd4, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd6, %fd5;
	div.rn.f64 	%fd7, %fd1, %fd6;
	cvt.rn.f32.f64	%f121, %fd7;
	div.rn.f64 	%fd8, %fd2, %fd6;
	cvt.rn.f32.f64	%f122, %fd8;
	rcp.rn.f64 	%fd9, %fd6;
	cvt.rn.f32.f64	%f123, %fd9;
	mov.b32 	 %r95, %f277;
	mov.b32 	 %r94, %f278;
	mov.b32 	 %r93, %f279;
	mov.b32 	 %r92, %f280;
	mov.u32 	%r87, 255;
	mov.u32 	%r96, -1082130432;
	mov.f32 	%f125, 0f5A0E1BCA;
	mov.f32 	%f126, 0f00000000;
	// inline asm
	call (%r82, %r83, %r84, %r85, %r86), _optix_trace_5, (%rd42, %f3, %f4, %f228, %f121, %f122, %f123, %f126, %f125, %f126, %r87, %r143, %r143, %r143, %r143, %r92, %r93, %r94, %r95, %r96);
	// inline asm
	mov.b32 	 %f280, %r82;
	mov.b32 	 %f279, %r83;
	mov.b32 	 %f278, %r84;
	mov.b32 	 %f277, %r85;
	mov.b32 	 %f30, %r86;
	setp.ltu.f32	%p7, %f30, 0f00000000;
	@%p7 bra 	BB0_38;

	sub.f32 	%f31, %f30, %f101;
	mul.f32 	%f270, %f102, %f31;
	mov.b32 	 %r11, %f270;
	and.b32  	%r98, %r11, 2147483647;
	setp.eq.s32	%p8, %r98, 0;
	@%p8 bra 	BB0_36;
	bra.uni 	BB0_6;

BB0_36:
	mov.f32 	%f235, 0f00000000;
	mov.f32 	%f164, 0f3F000000;
	mov.f32 	%f165, 0f3BBB989D;
	fma.rn.f32 	%f167, %f235, %f165, %f164;
	cvt.sat.f32.f32	%f168, %f167;
	mov.f32 	%f169, 0f4B400001;
	mov.f32 	%f170, 0f437C0000;
	fma.rm.f32 	%f171, %f168, %f170, %f169;
	add.f32 	%f172, %f171, 0fCB40007F;
	neg.f32 	%f173, %f172;
	mov.f32 	%f174, 0f3FB8AA3B;
	fma.rn.f32 	%f175, %f235, %f174, %f173;
	mov.f32 	%f176, 0f32A57060;
	fma.rn.f32 	%f177, %f235, %f176, %f175;
	mov.b32 	 %r140, %f171;
	shl.b32 	%r141, %r140, 23;
	mov.b32 	 %f178, %r141;
	ex2.approx.ftz.f32 	%f179, %f177;
	mul.f32 	%f269, %f179, %f178;
	bra.uni 	BB0_37;

BB0_6:
	mul.f32 	%f131, %f270, 0f3F22F983;
	cvt.rni.s32.f32	%r168, %f131;
	cvt.rn.f32.s32	%f132, %r168;
	mov.f32 	%f133, 0fBFC90FDA;
	fma.rn.f32 	%f134, %f132, %f133, %f270;
	mov.f32 	%f135, 0fB3A22168;
	fma.rn.f32 	%f136, %f132, %f135, %f134;
	mov.f32 	%f137, 0fA7C234C5;
	fma.rn.f32 	%f267, %f132, %f137, %f136;
	abs.f32 	%f34, %f270;
	shr.u32 	%r13, %r11, 23;
	bfe.u32 	%r99, %r11, 23, 8;
	add.s32 	%r100, %r99, -128;
	shr.u32 	%r101, %r100, 5;
	mov.u32 	%r102, 4;
	sub.s32 	%r103, %r102, %r101;
	mul.wide.s32 	%rd25, %r103, 4;
	add.s64 	%rd6, %rd1, %rd25;
	setp.leu.f32	%p9, %f34, 0f47CE4780;
	mov.u32 	%r161, %r168;
	mov.f32 	%f264, %f267;
	@%p9 bra 	BB0_17;

	setp.eq.f32	%p10, %f34, 0f7F800000;
	@%p10 bra 	BB0_16;
	bra.uni 	BB0_8;

BB0_16:
	mov.f32 	%f234, 0f00000000;
	mul.rn.f32 	%f264, %f270, %f234;
	mov.u32 	%r161, %r168;
	bra.uni 	BB0_17;

BB0_8:
	mov.u64 	%rd45, 0;
	mov.u64 	%rd43, __cudart_i2opi_f;
	mov.u32 	%r155, -6;
	mov.u64 	%rd44, %rd1;

BB0_9:
	.pragma "nounroll";
	mov.b32 	 %f240, %r86;
	sub.f32 	%f239, %f240, %f101;
	mul.f32 	%f238, %f102, %f239;
	mov.b32 	 %r147, %f238;
	shl.b32 	%r146, %r147, 8;
	or.b32  	%r145, %r146, -2147483648;
	ld.global.u32 	%r106, [%rd43];
	mad.wide.u32 	%rd28, %r106, %r145, %rd45;
	shr.u64 	%rd45, %rd28, 32;
	st.local.u32 	[%rd44], %rd28;
	add.s64 	%rd44, %rd44, 4;
	add.s64 	%rd43, %rd43, 4;
	add.s32 	%r155, %r155, 1;
	setp.ne.s32	%p11, %r155, 0;
	@%p11 bra 	BB0_9;

	and.b32  	%r18, %r11, -2147483648;
	st.local.u32 	[%rd5], %rd45;
	ld.local.u32 	%r156, [%rd6+8];
	ld.local.u32 	%r157, [%rd6+4];
	and.b32  	%r21, %r13, 31;
	setp.eq.s32	%p12, %r21, 0;
	@%p12 bra 	BB0_12;

	mov.u32 	%r107, 32;
	sub.s32 	%r108, %r107, %r21;
	shr.u32 	%r109, %r157, %r108;
	shl.b32 	%r110, %r156, %r21;
	add.s32 	%r156, %r109, %r110;
	ld.local.u32 	%r111, [%rd6];
	shr.u32 	%r112, %r111, %r108;
	shl.b32 	%r113, %r157, %r21;
	add.s32 	%r157, %r112, %r113;

BB0_12:
	shr.u32 	%r114, %r157, 30;
	shl.b32 	%r115, %r156, 2;
	add.s32 	%r159, %r114, %r115;
	shl.b32 	%r27, %r157, 2;
	shr.u32 	%r116, %r159, 31;
	shr.u32 	%r117, %r156, 30;
	add.s32 	%r28, %r116, %r117;
	setp.eq.s32	%p13, %r116, 0;
	@%p13 bra 	BB0_13;
	bra.uni 	BB0_14;

BB0_13:
	mov.u32 	%r158, %r18;
	mov.u32 	%r160, %r27;
	bra.uni 	BB0_15;

BB0_14:
	not.b32 	%r118, %r159;
	neg.s32 	%r160, %r27;
	setp.eq.s32	%p14, %r27, 0;
	selp.u32	%r119, 1, 0, %p14;
	add.s32 	%r159, %r119, %r118;
	xor.b32  	%r158, %r18, -2147483648;

BB0_15:
	cvt.u64.u32	%rd29, %r159;
	cvt.u64.u32	%rd30, %r160;
	bfi.b64 	%rd31, %rd29, %rd30, 32, 32;
	cvt.rn.f64.s64	%fd10, %rd31;
	mul.f64 	%fd11, %fd10, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f138, %fd11;
	neg.f32 	%f139, %f138;
	setp.eq.s32	%p15, %r158, 0;
	selp.f32	%f264, %f138, %f139, %p15;
	setp.eq.s32	%p16, %r18, 0;
	neg.s32 	%r120, %r28;
	selp.b32	%r161, %r28, %r120, %p16;

BB0_17:
	mov.f32 	%f229, 0f00000000;
	add.s32 	%r37, %r161, 1;
	and.b32  	%r38, %r37, 1;
	setp.eq.s32	%p17, %r38, 0;
	selp.f32	%f38, %f264, 0f3F800000, %p17;
	mul.rn.f32 	%f39, %f264, %f264;
	fma.rn.f32 	%f40, %f39, %f38, %f229;
	mov.f32 	%f265, 0fB94D4153;
	@%p17 bra 	BB0_19;

	mov.f32 	%f143, 0fBAB607ED;
	mov.f32 	%f144, 0f37CBAC00;
	fma.rn.f32 	%f265, %f144, %f39, %f143;

BB0_19:
	setp.ne.s32	%p18, %r38, 0;
	selp.f32	%f145, 0f3D2AAABB, 0f3C0885E4, %p18;
	fma.rn.f32 	%f146, %f265, %f39, %f145;
	selp.f32	%f147, 0fBEFFFFFF, 0fBE2AAAA8, %p18;
	fma.rn.f32 	%f148, %f146, %f39, %f147;
	fma.rn.f32 	%f269, %f148, %f40, %f38;
	and.b32  	%r121, %r37, 2;
	setp.eq.s32	%p19, %r121, 0;
	@%p19 bra 	BB0_21;

	mov.f32 	%f230, 0f00000000;
	mov.f32 	%f150, 0fBF800000;
	fma.rn.f32 	%f269, %f269, %f150, %f230;

BB0_21:
	@%p9 bra 	BB0_32;

	setp.eq.f32	%p21, %f34, 0f7F800000;
	@%p21 bra 	BB0_31;
	bra.uni 	BB0_23;

BB0_31:
	mov.f32 	%f233, 0f00000000;
	mul.rn.f32 	%f267, %f270, %f233;
	bra.uni 	BB0_32;

BB0_23:
	mov.u64 	%rd48, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
	mov.u32 	%r162, -6;
	mov.u64 	%rd47, %rd1;

BB0_24:
	.pragma "nounroll";
	mov.b32 	 %f243, %r86;
	sub.f32 	%f242, %f243, %f101;
	mul.f32 	%f241, %f102, %f242;
	mov.b32 	 %r150, %f241;
	shl.b32 	%r149, %r150, 8;
	or.b32  	%r148, %r149, -2147483648;
	ld.global.u32 	%r124, [%rd46];
	mad.wide.u32 	%rd34, %r124, %r148, %rd48;
	shr.u64 	%rd48, %rd34, 32;
	st.local.u32 	[%rd47], %rd34;
	add.s64 	%rd47, %rd47, 4;
	add.s64 	%rd46, %rd46, 4;
	add.s32 	%r162, %r162, 1;
	setp.ne.s32	%p22, %r162, 0;
	@%p22 bra 	BB0_24;

	and.b32  	%r42, %r11, -2147483648;
	st.local.u32 	[%rd5], %rd48;
	ld.local.u32 	%r163, [%rd6+8];
	ld.local.u32 	%r164, [%rd6+4];
	and.b32  	%r45, %r13, 31;
	setp.eq.s32	%p23, %r45, 0;
	@%p23 bra 	BB0_27;

	mov.u32 	%r125, 32;
	sub.s32 	%r126, %r125, %r45;
	shr.u32 	%r127, %r164, %r126;
	shl.b32 	%r128, %r163, %r45;
	add.s32 	%r163, %r127, %r128;
	ld.local.u32 	%r129, [%rd6];
	shr.u32 	%r130, %r129, %r126;
	shl.b32 	%r131, %r164, %r45;
	add.s32 	%r164, %r130, %r131;

BB0_27:
	shr.u32 	%r132, %r164, 30;
	shl.b32 	%r133, %r163, 2;
	add.s32 	%r166, %r132, %r133;
	shl.b32 	%r51, %r164, 2;
	shr.u32 	%r134, %r166, 31;
	shr.u32 	%r135, %r163, 30;
	add.s32 	%r52, %r134, %r135;
	setp.eq.s32	%p24, %r134, 0;
	@%p24 bra 	BB0_28;
	bra.uni 	BB0_29;

BB0_28:
	mov.u32 	%r165, %r42;
	mov.u32 	%r167, %r51;
	bra.uni 	BB0_30;

BB0_29:
	not.b32 	%r136, %r166;
	neg.s32 	%r167, %r51;
	setp.eq.s32	%p25, %r51, 0;
	selp.u32	%r137, 1, 0, %p25;
	add.s32 	%r166, %r137, %r136;
	xor.b32  	%r165, %r42, -2147483648;

BB0_30:
	cvt.u64.u32	%rd35, %r166;
	cvt.u64.u32	%rd36, %r167;
	bfi.b64 	%rd37, %rd35, %rd36, 32, 32;
	cvt.rn.f64.s64	%fd12, %rd37;
	mul.f64 	%fd13, %fd12, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f151, %fd13;
	neg.f32 	%f152, %f151;
	setp.eq.s32	%p26, %r165, 0;
	selp.f32	%f267, %f151, %f152, %p26;
	setp.eq.s32	%p27, %r42, 0;
	neg.s32 	%r138, %r52;
	selp.b32	%r168, %r52, %r138, %p27;

BB0_32:
	mov.f32 	%f231, 0f00000000;
	and.b32  	%r61, %r168, 1;
	setp.eq.s32	%p28, %r61, 0;
	selp.f32	%f49, %f267, 0f3F800000, %p28;
	mul.rn.f32 	%f50, %f267, %f267;
	fma.rn.f32 	%f51, %f50, %f49, %f231;
	mov.f32 	%f268, 0fB94D4153;
	@%p28 bra 	BB0_34;

	mov.f32 	%f156, 0fBAB607ED;
	mov.f32 	%f157, 0f37CBAC00;
	fma.rn.f32 	%f268, %f157, %f50, %f156;

BB0_34:
	setp.ne.s32	%p29, %r61, 0;
	selp.f32	%f158, 0f3D2AAABB, 0f3C0885E4, %p29;
	fma.rn.f32 	%f159, %f268, %f50, %f158;
	selp.f32	%f160, 0fBEFFFFFF, 0fBE2AAAA8, %p29;
	fma.rn.f32 	%f161, %f159, %f50, %f160;
	fma.rn.f32 	%f270, %f161, %f51, %f49;
	and.b32  	%r139, %r168, 2;
	setp.eq.s32	%p30, %r139, 0;
	@%p30 bra 	BB0_37;

	mov.f32 	%f232, 0f00000000;
	mov.f32 	%f163, 0fBF800000;
	fma.rn.f32 	%f270, %f270, %f163, %f232;

BB0_37:
	mov.b32 	 %f237, %r86;
	sub.f32 	%f236, %f237, %f101;
	mul.f32 	%f180, %f270, 0f00000000;
	mul.f32 	%f181, %f280, %f269;
	sub.f32 	%f182, %f181, %f180;
	mul.f32 	%f183, %f280, %f270;
	fma.rn.f32 	%f184, %f269, 0f00000000, %f183;
	cvt.f64.f32	%fd14, %f236;
	abs.f64 	%fd15, %fd14;
	cvt.rn.f32.f64	%f185, %fd15;
	add.f32 	%f186, %f185, 0f00000000;
	rcp.rn.f32 	%f187, %f186;
	mul.f32 	%f188, %f182, %f187;
	mul.f32 	%f189, %f184, %f187;
	mul.f32 	%f190, %f236, %f187;
	mul.f32 	%f191, %f187, 0f00000000;
	mul.f32 	%f192, %f191, %f191;
	fma.rn.f32 	%f193, %f190, %f190, %f192;
	rcp.rn.f32 	%f194, %f193;
	mul.f32 	%f195, %f189, %f191;
	fma.rn.f32 	%f196, %f188, %f190, %f195;
	mul.f32 	%f197, %f194, %f196;
	mul.f32 	%f198, %f189, %f190;
	mul.f32 	%f199, %f188, %f191;
	sub.f32 	%f200, %f198, %f199;
	mul.f32 	%f201, %f194, %f200;
	add.f32 	%f259, %f259, %f197;
	add.f32 	%f258, %f258, %f201;
	mul.f32 	%f202, %f279, %f197;
	mul.f32 	%f203, %f201, 0f00000000;
	sub.f32 	%f204, %f202, %f203;
	mul.f32 	%f205, %f197, 0f00000000;
	fma.rn.f32 	%f206, %f279, %f201, %f205;
	mul.f32 	%f207, %f187, %f204;
	mul.f32 	%f208, %f187, %f206;
	mul.f32 	%f209, %f191, %f208;
	fma.rn.f32 	%f210, %f190, %f207, %f209;
	mul.f32 	%f211, %f194, %f210;
	mul.f32 	%f212, %f190, %f208;
	mul.f32 	%f213, %f191, %f207;
	sub.f32 	%f214, %f212, %f213;
	mul.f32 	%f215, %f194, %f214;
	add.f32 	%f261, %f261, %f211;
	add.f32 	%f260, %f260, %f215;
	mul.f32 	%f216, %f278, %f211;
	mul.f32 	%f217, %f215, 0f00000000;
	sub.f32 	%f218, %f216, %f217;
	mul.f32 	%f219, %f211, 0f00000000;
	fma.rn.f32 	%f220, %f278, %f215, %f219;
	mul.f32 	%f221, %f187, %f218;
	mul.f32 	%f222, %f187, %f220;
	mul.f32 	%f223, %f191, %f222;
	fma.rn.f32 	%f224, %f190, %f221, %f223;
	mul.f32 	%f225, %f190, %f222;
	mul.f32 	%f226, %f191, %f221;
	sub.f32 	%f227, %f225, %f226;
	fma.rn.f32 	%f263, %f194, %f224, %f263;
	fma.rn.f32 	%f262, %f194, %f227, %f262;
	add.s32 	%r154, %r154, 1;

BB0_38:
	add.s32 	%r153, %r153, 1;
	setp.lt.s32	%p31, %r153, %r76;
	@%p31 bra 	BB0_4;

BB0_39:
	add.s32 	%r151, %r151, 1;
	setp.lt.s32	%p32, %r151, %r5;
	@%p32 bra 	BB0_2;

BB0_40:
	ld.const.u64 	%rd38, [params];
	cvta.to.global.u64 	%rd39, %rd38;
	mad.lo.s32 	%r142, %r69, %r71, %r68;
	mul.wide.u32 	%rd40, %r142, 32;
	add.s64 	%rd41, %rd39, %rd40;
	st.global.v2.f32 	[%rd41], {%f259, %f258};
	st.global.v2.f32 	[%rd41+8], {%f261, %f260};
	st.global.v2.f32 	[%rd41+16], {%f263, %f262};
	st.global.u32 	[%rd41+24], %r154;
	ret;
}

	// .globl	__closesthit__ch
.visible .entry __closesthit__ch(

)
{
	.reg .f32 	%f<52>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<15>;


	// inline asm
	call (%r1), _optix_read_primitive_idx, ();
	// inline asm
	// inline asm
	call (%rd1), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd2, [%rd1+8];
	mul.wide.s32 	%rd3, %r1, 12;
	add.s64 	%rd4, %rd2, %rd3;
	ld.f32 	%f7, [%rd4];
	ld.f32 	%f8, [%rd4+4];
	ld.f32 	%f9, [%rd4+8];
	ld.const.u64 	%rd5, [params+24];
	cvta.to.global.u64 	%rd6, %rd5;
	add.s64 	%rd7, %rd6, %rd3;
	ld.global.u32 	%r6, [%rd7];
	ld.global.u32 	%r7, [%rd7+4];
	ld.global.u32 	%r8, [%rd7+8];
	// inline asm
	call (%f1, %f2), _optix_get_triangle_barycentrics, ();
	// inline asm
	mov.f32 	%f10, 0f3F800000;
	sub.f32 	%f11, %f10, %f1;
	sub.f32 	%f12, %f11, %f2;
	ld.u64 	%rd8, [%rd1];
	mul.wide.s32 	%rd9, %r6, 12;
	add.s64 	%rd10, %rd8, %rd9;
	ld.f32 	%f13, [%rd10];
	ld.f32 	%f14, [%rd10+4];
	ld.f32 	%f15, [%rd10+8];
	mul.wide.s32 	%rd11, %r7, 12;
	add.s64 	%rd12, %rd8, %rd11;
	ld.f32 	%f16, [%rd12];
	mul.f32 	%f17, %f2, %f16;
	ld.f32 	%f18, [%rd12+4];
	mul.f32 	%f19, %f2, %f18;
	ld.f32 	%f20, [%rd12+8];
	mul.f32 	%f21, %f2, %f20;
	fma.rn.f32 	%f22, %f13, %f1, %f17;
	fma.rn.f32 	%f23, %f14, %f1, %f19;
	fma.rn.f32 	%f24, %f15, %f1, %f21;
	mul.wide.s32 	%rd13, %r8, 12;
	add.s64 	%rd14, %rd8, %rd13;
	ld.f32 	%f25, [%rd14];
	ld.f32 	%f26, [%rd14+4];
	ld.f32 	%f27, [%rd14+8];
	fma.rn.f32 	%f28, %f12, %f25, %f22;
	fma.rn.f32 	%f29, %f12, %f26, %f23;
	fma.rn.f32 	%f30, %f12, %f27, %f24;
	mul.f32 	%f31, %f29, %f29;
	fma.rn.f32 	%f32, %f28, %f28, %f31;
	fma.rn.f32 	%f33, %f30, %f30, %f32;
	sqrt.rn.f32 	%f34, %f33;
	div.rn.f32 	%f35, %f28, %f34;
	div.rn.f32 	%f36, %f29, %f34;
	div.rn.f32 	%f37, %f30, %f34;
	// inline asm
	call (%f3), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f4), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f5), _optix_get_world_ray_direction_z, ();
	// inline asm
	mul.f32 	%f38, %f4, %f4;
	fma.rn.f32 	%f39, %f3, %f3, %f38;
	fma.rn.f32 	%f40, %f5, %f5, %f39;
	sqrt.rn.f32 	%f41, %f40;
	div.rn.f32 	%f42, %f3, %f41;
	div.rn.f32 	%f43, %f4, %f41;
	div.rn.f32 	%f44, %f5, %f41;
	mul.f32 	%f45, %f36, %f43;
	fma.rn.f32 	%f46, %f35, %f42, %f45;
	fma.rn.f32 	%f47, %f37, %f44, %f46;
	mul.f32 	%f48, %f47, 0f3F4CCCCD;
	fma.rn.f32 	%f49, %f7, %f48, 0f3E4CCCCD;
	fma.rn.f32 	%f50, %f8, %f48, 0f3E4CCCCD;
	fma.rn.f32 	%f51, %f9, %f48, 0f3E4CCCCD;
	mov.b32 	 %r2, %f49;
	// inline asm
	call _optix_set_payload_0, (%r2);
	// inline asm
	mov.b32 	 %r3, %f50;
	// inline asm
	call _optix_set_payload_1, (%r3);
	// inline asm
	mov.b32 	 %r4, %f51;
	// inline asm
	call _optix_set_payload_2, (%r4);
	// inline asm
	// inline asm
	call (%f6), _optix_get_ray_tmax, ();
	// inline asm
	mov.b32 	 %r5, %f6;
	// inline asm
	call _optix_set_payload_4, (%r5);
	// inline asm
	ret;
}


